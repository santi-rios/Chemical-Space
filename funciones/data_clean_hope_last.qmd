---
title: data cleaning
---

## Data

```{r}
# Load required packages
library(dplyr)
library(tidyr)
library(stringr)

#' Process a single CSV file
#'
#' This function reads a CSV file, reshapes it from wide to long format,
#' calculates the percentage for each year relative to the "Total" value,
#' cleans the year column, and filters out rows where Country is "Total"
#' or where the year is before 1996. It also adds a 'source_file' column
#' to track the origin of the data.
#'
#' @param file_path A character string specifying the path to the CSV file.
#'
#' @return A tibble containing the processed data with a 'source_file' column.
process_single_csv <- function(file_path) {
  file_name <- basename(file_path)
  
  # Read and clean data
  df <- read.csv(file_path, stringsAsFactors = FALSE) %>%
    mutate(Country = trimws(Country))
  
  # Reshape data safely
  df_long <- df %>%
    pivot_longer(
      cols = starts_with("X"),
      names_to = "year",
      values_to = "value_raw",
      values_drop_na = TRUE,
      values_transform = list(value_raw = as.numeric)
    )
  
  # Calculate totals per year
  totals <- df_long %>%
    filter(Country == "Total") %>%
    group_by(year) %>%
    summarise(
      total_value = if(n() == 0) NA_real_ else sum(value_raw, na.rm = TRUE),
      .groups = 'drop'
    )
  
  # Calculate percentages
  df_percentage <- df_long %>%
    filter(Country != "Total") %>%
    left_join(totals, by = "year") %>%
    mutate(
      percentage = if_else(
        is.na(total_value) | total_value == 0,
        NA_real_,
        (value_raw / total_value) * 100
      )
    )
  
  # Final cleaning
  df_clean <- df_percentage %>%
    mutate(
      year = as.numeric(str_remove(year, "X")),
      source_file = file_name
    ) %>%
    filter(year >= 1996) %>%
    select(-total_value)
  
  return(df_clean)
}

#' Process and merge all CSV files in a folder
#'
#' This function scans a specified folder for CSV files, applies the
#' \code{process_single_csv} function to each file, merges the processed
#' data into a single data frame, and optionally writes the merged data to a CSV file.
#'
#' @param folder_path A character string specifying the path to the folder containing CSV files.
#' @param output_file (Optional) A character string specifying the path where the merged CSV file
#'   should be saved. If \code{NULL}, the file is not written.
#'
#' @return A tibble containing the merged processed data from all CSV files, including a 'source_file' column.
process_csv_folder <- function(folder_path, output_file = NULL) {
  csv_files <- list.files(folder_path, "\\.csv$", full.names = TRUE)
  merged_data <- lapply(csv_files, process_single_csv) %>% bind_rows()
  
  if (!is.null(output_file)) {
    write.csv(merged_data, output_file, row.names = FALSE)
  }
  
  return(merged_data)
}

# Example usage:
merged_df <- process_csv_folder("./data4", output_file = "./data5/merged_data.csv")
```

### Add Country Codes and extra info

```{r country_codes}
country_codes <- read.csv("./data/country_codes.csv")
```



::: {.callout-important}

Before executing, change in the merged the `,` to `-` in the `Country` column.	  
:::

```{r}
tictoc::tic()
library(readxl)
library(writexl)
library(dplyr)
library(stringr)

# Read the first file
df_first <- read.csv("./data5/merged_data.csv") # Rare-Earths


# Read the lookup file
df_lookup <- read_excel("./data/lookup.xlsx")
#   Country year  percentage
# 1      AE 1996 0.002591378
# 2      AE 1997 0.000633066
# 3      AE 1999 0.000608049
# 4      AE 2001 0.003855382
# 5      AE 2002 0.000841470
# 6      AE 2003 0.001065979


# For convenience, rename columns to simpler names
# Make sure these match the actual column names in your file
df_lookup <- df_lookup %>%
  rename(
    alpha2 = `Alpha-2`,
    alpha3 = `Alpha-3`,
    country_name = `Country`
  )

# A helper function that splits a code string (e.g. "AE-AT-EG")
# and looks up each Alpha-2 code in df_lookup
### ATTENTION
#### we need to add a column with "source = file_name"
convert_codes <- function(code_str) {
  codes <- str_split(code_str, "-", simplify = TRUE)
  codes <- codes[codes != ""]  # remove any empty parts
  
  iso3_list <- c()
  name_list <- c()
  
  for (c in codes) {
    # Find the matching row
    match_row <- df_lookup %>% filter(alpha2 == c)
    if (nrow(match_row) == 1) {
      iso3_list <- c(iso3_list, match_row$alpha3)
      name_list <- c(name_list, match_row$country_name)
    } else {
      iso3_list <- c(iso3_list, "???")
      name_list <- c(name_list, "Unknown")
    }
  }
  
  iso3_str <- paste(iso3_list, collapse = "-")
  country_names_str <- paste(name_list, collapse = ", ")
  
  return(list(iso3c = iso3_str, country_name = country_names_str))
}

# Vectorize the function so we can apply it easily
convert_codes_vec <- Vectorize(convert_codes, SIMPLIFY = FALSE)

# Apply it to the "Country" column in df_first
results <- convert_codes_vec(df_first$Country)

# results is a list of lists; extract iso3c and country_name into separate vectors
df_first$iso3c <- sapply(results, function(x) x$iso3c)
df_first$country_name <- sapply(results, function(x) x$country_name)

# Write out to Excel
write.csv(df_first, "./data5/merged2.csv")
tictoc::toc()
```

::: {.callout-important}

Before executing, change in the merged data:

  - delete first column
  - Country to iso2c
  - country_name to country
  - delete value_raw
  - source_file to chemical
  - delete ` (*)`, `null` and `unknown` 
:::

```{r}	

df <- read.csv("./data5/merged2.csv")

df2 <- df |>
  dplyr::select(-X) |>
  dplyr::rename(
    iso2c = Country,
    country = country_name,
    chemical = source_file
  ) |>
  dplyr::filter(!stringr::str_detect(chemical, "null|unknown|\\*")) |>
  dplyr::mutate(
    year = as.numeric(year),
    percentage = as.numeric(percentage),
    chemical = case_when(
      chemical == "absolute_counting_colabs_raras.csv" ~ "Rare-Earths",
      chemical == "absolute_counting_colabs_organic.csv" ~ "Organic",
      chemical == "absolute_counting_colabs_metalOrganic.csv" ~ "Organometallic",
      chemical == "absolute_counting_colabs_totalSpace.csv" ~ "All",
      TRUE ~ chemical
    ),
    is_collab = if_else(stringr::str_detect(iso2c, "-"), TRUE, FALSE)
  )

write.csv(df2, "./data5/merged2_2.csv")
```


```{r country_codes}
country_info <- read.csv("./data/df_coordinates_good.csv")

country_info2 <- country_info |>
  dplyr::mutate(
    continent = countrycode::countrycode(
      iso2c, 
      origin = 'iso2c', 
      destination = 'continent')
  )

write.csv(country_info2, "./data5/df_coordinates_good2.csv")

```


::: {.callout-important}

clean manual south and north america. 

clean manual contrynames
:::

```{r}

df_a <- read.csv("./data5/merged2_3.csv")
df_b <- read.csv("./data5/df_coordinates_good2.csv")

df_c <- df_a |>
  dplyr::left_join(df_b, by = c("iso2c")) |>
  dplyr::rename(
    region = continent
  )

write.csv(df_c, "./data5/merged3.csv")
arrow::write_parquet(df_c, "./data5/merged3.parquet")
```

Top 20 countries in collabs

```{r}
arrow::read_parquet("./data5/merged3.parquet") |>
  dplyr::filter(is_collab == TRUE) |>
  group_by(iso2c) %>% 
  summarise(val = sum(percentage, na.rm = TRUE)) %>%
 arrange(desc(val)) %>%
 head(25) %>%
 pull(iso2c)

```

```{r}
library(gapminder)
library(dplyr)

gap_with_colors <-
  data.frame(gapminder,
    cc = I(country_colors[match(
      gapminder$country,
      names(country_colors)
    )])
  )

View(gap_with_colors)

gap_with_colors_colours <- gap_with_colors %>%
  dplyr::group_by(country) %>%
  dplyr::summarise(
    cc = first(cc)
  ) %>%
  dplyr::mutate(
    cc = dplyr::if_else(
      country %in% c("China", "United States", "India", "Germany",
                      "Japan", "United Kingdom", "France", "Russia", "Mexico",
                      "Colombia", "Brazil", "Ecuador", "Argentina"
                      ),
      c("#c5051b", "#0a3161", "#ff671f", "#000000",
        "#995162", "#3b5091", "#000091", "#d51e9b",
        "#006341", "#fcd116", "#009b3a", "#ffdd00", "#74acdf")[match(country,
          c("China", "United States", "India", "Germany",
            "Japan", "United Kingdom", "France", "Russia", "Mexico",
            "Colombia", "Brazil", "Ecuador", "Argentina")
        )],
      cc
    )
  )

View(gap_with_colors_colours)

read.csv("./data5/merged3.csv") |>
  dplyr::left_join(gap_with_colors_colours, by = c("country" = "country")) |>
  write.csv("./data6/df_cc_2.csv", row.names = FALSE)

```

```{r}
library(tidyverse)

# Helper function to convert ISO2 codes to flag emojis
flag_emoji <- function(iso) {
  sapply(iso, function(x) {
    x <- toupper(x)
    if (nchar(x) == 2) {
      ints <- utf8ToInt(x) - utf8ToInt("A") + 127462
      intToUtf8(ints)
    } else {
      NA_character_
    }
  })
}

read.csv("./data6/df_cc_3.csv") |>
  dplyr::mutate(
    year = as.numeric(year),
    percentage = as.numeric(percentage),
    country = dplyr::case_when(
      country == "United States of America" ~ "United States",
      TRUE ~ country
    ),
    blue_group = iso2c %in% c(
      "DE-US", "GB-US", "IN-US",
      "CA-US", "JP-US", "FR-US",
      "IT-US", "KR-US", "ES-US"
    ),
    red_group = iso2c %in% c(
      "CN-US", "CN-JP", "CN-DE", "DE-RU",
      "DE-FR", "ES-GB", "DE-ES", "ES-FR",
      "FR-GB", "DE-GB", "ES-IT", "DE-IN",
      "CN-HK", "CH-FR", "CN-GB", "FR-RU"
    ),
    color_group = dplyr::case_when(
      blue_group ~ "blue",
      red_group ~ "red",
      TRUE ~ "other"
    )
  ) |>
  dplyr::group_by(color_group) |>
  dplyr::mutate(
    iso_rank = dplyr::dense_rank(iso2c),
    max_rank = max(iso_rank)
  ) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    cc = dplyr::case_when(
      color_group == "blue" ~ scales::col_numeric(
        palette = c("#00264c", "#2c2f32"),
        domain = c(1, max_rank)
      )(iso_rank),
      color_group == "red" ~ scales::col_numeric(
        palette = c("#ff9797", "#4c0000"),
        domain = c(1, max_rank)
      )(iso_rank),
      TRUE ~ cc
    ),
    emo = dplyr::if_else(!is_collab, flag_emoji(iso2c), NA_character_)
  ) |>
  dplyr::mutate(
        emoji = countrycode::countrycode(
            country,
            origin = "country.name",
            destination = "unicode.symbol"
        )
    ) |>
  arrow::write_parquet("./data6/df_cc_3.parquet")

```

```{r}
library(dplyr)
library(scales)
library(countrycode)
library(arrow)

# Read in the data and assign groups
df <- read.csv("./data6/df_cc_4.csv") %>%
  mutate(
    year = as.numeric(year),
    percentage = as.numeric(percentage),
    blue_group = iso2c %in% c(
      "DE-US", "GB-US", "IN-US",
      "CA-US", "JP-US", "FR-US",
      "IT-US", "KR-US", "ES-US"
    ),
    red_group = iso2c %in% c(
      "CN-US", "CN-JP", "CN-DE", "DE-RU",
      "DE-FR", "ES-GB", "DE-ES", "ES-FR",
      "FR-GB", "DE-GB", "ES-IT", "DE-IN",
      "CN-HK", "CH-FR", "CN-GB", "FR-RU"
    ),
    color_group = case_when(
      blue_group ~ "blue",
      red_group ~ "red",
      TRUE ~ "other"
    )
  )

# Build lookup for blue_group
blue_codes <- unique(df$iso2c[df$blue_group])
blue_palette <- col_numeric(
  palette = c("#76a4d2", "#002852"),
  domain = c(1, length(blue_codes))
)
blue_color_map <- setNames(blue_palette(seq_along(blue_codes)), blue_codes)

# Build lookup for red_group
red_codes <- unique(df$iso2c[df$red_group])
red_palette <- col_numeric(
  palette = c("#fe0000", "#e79797"),
  domain = c(1, length(red_codes))
)
red_color_map <- setNames(red_palette(seq_along(red_codes)), red_codes)

# Map the colors back to the dataframe
df <- df %>%
  mutate(
    cc = case_when(
      blue_group ~ blue_color_map[iso2c],
      red_group ~ red_color_map[iso2c],
      TRUE ~ cc  # retain any pre-existing values for "other"
    )
    # emo = if_else(!is_collab, flag_emoji(iso2c), NA_character_),
    # emoji = countrycode(
    #   country,
    #   origin = "country.name",
    #   destination = "unicode.symbol"
    # )
  )

df <- df %>%
  mutate(
    region = case_when(
      country == "Bolivia" ~ "South America",
      TRUE ~ region
    )
  )

# Write out the final dataframe
arrow::write_parquet(df, "./data6/df_cc_4.parquet")
```


```{r}
# library(ggplot2)

# world_data <- map_data("world") %>%
#   filter(region != "Antarctica") %>%
#   rename(country = region, lng = long) %>%
#   mutate(
#     country = case_when(
#       country == "USA" ~ "United States",
#       country == "UK" ~ "United Kingdom",
#       TRUE ~ country
#     )
#   )

# Run this once during development:
if (!file.exists("data/world_data.parquet")) {
  library(ggplot2)
  library(dplyr)
  library(arrow)
  
  world_data <- map_data("world") %>%
    filter(region != "Antarctica") %>%
    rename(country = region, lng = long) %>%
    mutate(
      country = case_when(
        country == "USA" ~ "United States",
        country == "UK" ~ "United Kingdom",
        # Add more mappings as needed
        TRUE ~ country
      )
    )
  
  # Create directory if it doesn't exist
  if (!dir.exists("data")) dir.create("data")
  
  # Save the processed data
  write_parquet(world_data, "data/world_data.parquet")
}

# # Then in your app.R, replace the world_data computation with:
# world_data <- readRDS("data/world_data.rds")

```